[project]
name = "llm-eval-test"
version = "0.2.1"
description = "LLM Evaluation Test Tool"
authors = [
    {name = "Samuel Monson", email = "smonson@redhat.com"},
]
dependencies = [
    "lm-eval[api]==0.4.8",
    "unitxt==1.14.0",
    "torch>=1.8",
]
requires-python = "<4.0,>=3.11"
readme = "README.md"

[project.optional-dependencies]
leaderboard = [
    "lm-eval[ifeval,math,sentencepiece]>=0.4.8",
]

# Use cpu pytorch to avoid downloading cuda
[build-system]
requires = ["pdm-backend"]
build-backend = "pdm.backend"

[project.scripts]
llm-eval-test = "llm_eval_test.__main__:eval_cli"

[dependency-groups]
dev = [
    "pre-commit>=4.1.0",
    "ruff>=0.11.2",
]

[tool.ruff]
line-length = 120
src = ["src"]

[tool.ruff.lint]
extend-select = [
  "I",    # isort
  "B",    # flake8-bugbear
  "C4",   # flake8-comprehensions
  "FA",   # flake8-future-annotations
  "PGH",  # pygrep-hooks
  "RUF",  # ruff
  "W",    # pycodestyle
  "UP",   # pyupgrade
  "YTT",  # flake8-2020
]
extend-ignore = ["B018", "B019", "RUF018"]

[tool.pdm]
distribution = true
[[tool.pdm.source]]
name = "torch-cpu"
url = "https://download.pytorch.org/whl/cpu"
verify_ssl = true
